{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675a86c2-739a-4af8-b06f-0dc11239cb24",
   "metadata": {},
   "source": [
    "## Installing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39755a62-a911-4e7c-b3d8-d4be639f8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!!pip -q install langchain\n",
    "!pip -q install openai\n",
    "!pip -q install tiktoken\n",
    "!pip -q install faiss-cpu\n",
    "!pip -q install langchain_experimental\n",
    "!pip -q install openai\n",
    "!pip -q install PyPDF2\n",
    "!pip -q install templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c671e13a-a33e-48ee-aaf8-e773f52e2896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycryptodome\n",
      "  Obtaining dependency information for pycryptodome from https://files.pythonhosted.org/packages/a7/88/5e83de10450027c96c79dc65ac45e9d0d7a7fef334f39d3789a191f33602/pycryptodome-3.21.0-cp36-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading pycryptodome-3.21.0-cp36-abi3-macosx_10_9_universal2.whl.metadata (3.4 kB)\n",
      "Downloading pycryptodome-3.21.0-cp36-abi3-macosx_10_9_universal2.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pycryptodome\n",
      "Successfully installed pycryptodome-3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pycryptodome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cbe71a-b63d-4aa9-bd27-f27539b31e22",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7b773d1-a8b0-404a-9749-bdbd493d11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = 'MYAPIKEY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64be2220-ec1f-48a0-bc75-af3186248f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74621efc-d1d4-4d75-896e-2b6a038551ae",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30eb623f-b23a-4e55-86a5-2ec6946b2a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_pdf(pdf_path):\n",
    "    \"\"\"Reads and extracts text from a single PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        file = PdfReader(pdf_path)\n",
    "        for page in file.pages:\n",
    "            extracted_text = page.extract_text()\n",
    "            if extracted_text:\n",
    "                text += extracted_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def chunk_text(raw_text):\n",
    "    \"\"\"Splits raw text into smaller chunks for better processing.\"\"\"\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=900,\n",
    "        chunk_overlap=300,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(raw_text)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def get_vectorstore(chunks):\n",
    "    \"\"\"Creates a FAISS vector store from the text chunks.\"\"\"\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "    vectorstore = FAISS.from_texts(texts=chunks, embedding=embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def get_convo_chain(vectorstore):\n",
    "    \"\"\"Initializes a conversational retrieval chain with memory.\"\"\"\n",
    "    llm = ChatOpenAI(openai_api_key=openai.api_key)\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    convo_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "    return convo_chain\n",
    "\n",
    "\n",
    "def chat_user_input(user_query, convo_chain):\n",
    "    \"\"\"Handles user input and returns the chatbot's response.\"\"\"\n",
    "    response = convo_chain({'question': user_query})\n",
    "    chat_history = response['chat_history']\n",
    "    return chat_history[-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465da71c-a484-4947-b449-1aefb713706b",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e167503b-8074-413a-be05-074ef08ff0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading PDF from: /Users/ravjotsingh/Downloads/Fall 2024/DATA 255 Deep Learning/Class Demos/SJSUReport/DonationsGuidelines.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/v81nyhcx34j6495f4q71kk280000gn/T/ipykernel_50863/3128405017.py:37: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask any query regarding your data or enter 'quit' to exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is the pdf about?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/v81nyhcx34j6495f4q71kk280000gn/T/ipykernel_50863/3128405017.py:48: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = convo_chain({'question': user_query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot: The PDF appears to be a set of guidelines and information about donations to the Spartan Food Pantry at San Jose State University. It includes details on what items can be donated, how to organize donation drives, and general guidelines for donations.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what are the key concepts and guidelines in the pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot: The key principles and guidelines for donations to the Spartan Food Pantry at San Jose State University include donating quality items that you would use yourself, providing items in individual serving sizes that are easily opened or microwavable, focusing on healthy options like organic, BPA free, whole/multi-grain, low-sodium foods, ensuring original manufacturer sealed packaging is in place, being aware of food dates, and avoiding sugary items. Additionally, monetary donations are appreciated, and organizing a food and/or toiletry drive with your organization is encouraged with prior coordination. Donations can be made in person or via Amazon Wishlist for bulk purchases.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  where this food is used ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot: The food from the Spartan Food Pantry at San Jose State University is used to support students in need on campus.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Summarize the chat for today\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot: Today's chat provided information on how to donate to the Spartan Food Pantry at San Jose State University. The pantry accepts monetary donations through their website, encourages organizing food/toiletry drives, and provides a list of specific items needed for donation. They also offer guidelines for donating, including the types of items needed and drop-off locations. Additionally, they mentioned the option of purchasing items from their Amazon Wishlist for bulk donations.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Define the path for the PDF file\n",
    "    pdf_path = os.path.join(\"SJSUReport\", \"DonationsGuidelines.pdf\")\n",
    "    \n",
    "    # Check if the PDF file exists\n",
    "    if not os.path.isfile(pdf_path):\n",
    "        print(f\"Error: The file {pdf_path} does not exist. Please check the file path.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Reading PDF from: {os.path.abspath(pdf_path)}\")\n",
    "\n",
    "    # Extract text from the PDF\n",
    "    pdf_content = get_text_from_pdf(pdf_path)\n",
    "    if not pdf_content.strip():\n",
    "        print(\"No text was extracted from the PDF. Please ensure it contains extractable text.\")\n",
    "        return\n",
    "\n",
    "    # Split text into chunks\n",
    "    chunks = chunk_text(pdf_content)\n",
    "\n",
    "    # Create vector store\n",
    "    vectorstore = get_vectorstore(chunks)\n",
    "\n",
    "    # Get conversation chain\n",
    "    convo_chain = get_convo_chain(vectorstore)\n",
    "\n",
    "    print(\"Ask any query regarding your data or enter 'quit' to exit\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() == \"quit\":\n",
    "            break\n",
    "        response = chat_user_input(user_query, convo_chain)\n",
    "        print(\"ChatBot:\", response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
